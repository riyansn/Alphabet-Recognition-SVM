{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Define-function\" data-toc-modified-id=\"Define-function-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Define function</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preparation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></span></li></ul></li><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Flattening-The-Image\" data-toc-modified-id=\"Flattening-The-Image-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Flattening The Image</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-Test-Splitting\" data-toc-modified-id=\"Train-Test-Splitting-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Train Test Splitting</a></span></li><li><span><a href=\"#Pipelining\" data-toc-modified-id=\"Pipelining-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Pipelining</a></span></li></ul></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Precision,-Recall,-F1-score-and-Accuracy\" data-toc-modified-id=\"Precision,-Recall,-F1-score-and-Accuracy-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Precision, Recall, F1-score and Accuracy</a></span></li></ul></li><li><span><a href=\"#Save-the-model\" data-toc-modified-id=\"Save-the-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Save the model</a></span></li><li><span><a href=\"#Load-the-model\" data-toc-modified-id=\"Load-the-model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Load the model</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:42:14.364870Z",
     "iopub.status.busy": "2022-10-19T04:42:14.364488Z",
     "iopub.status.idle": "2022-10-19T04:42:14.371422Z",
     "shell.execute_reply": "2022-10-19T04:42:14.370463Z",
     "shell.execute_reply.started": "2022-10-19T04:42:14.364835Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearnex import patch_sklearn\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:38:42.908426Z",
     "iopub.status.busy": "2022-10-19T04:38:42.906982Z",
     "iopub.status.idle": "2022-10-19T04:38:42.918226Z",
     "shell.execute_reply": "2022-10-19T04:38:42.916728Z",
     "shell.execute_reply.started": "2022-10-19T04:38:42.908350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load image from csv and return image on folder\n",
    "def csv_to_image(csv_path,csv_image_shape_initialized, image_shape_target, image_folder_path):\n",
    "    \n",
    "    '''\n",
    "    something to note :\n",
    "    - don't include the header on the csv data\n",
    "    - each row save the image where the first column is the label followed the pixel value\n",
    "    - this function just good at minimize image not to enlarge. since interpolation used are good for minimize\n",
    "    \n",
    "    args :\n",
    "    csv_path : where the csv that will be loaded saved\n",
    "    csv_image_shape : image_shape saved on the csv\n",
    "    image_shape_target : size of the image you want as the output\n",
    "    \n",
    "    '''\n",
    "    count = 1\n",
    "    \n",
    "    #get list alphabet\n",
    "    Alphabet_Mapping_List = list(string.ascii_uppercase)\n",
    "    \n",
    "    # Make folder of each alphabet, if there no folder with a specific alphabel listed on Alphabel_Mapping_list then it will make new folder\n",
    "    for alphabet in Alphabet_Mapping_List:\n",
    "        path = image_folder_path + '/' + alphabet\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "    \n",
    "    \n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        # make a object that can help to iterate over lines of CSV file\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        \n",
    "        # Iterate over lines\n",
    "        for row in reader:\n",
    "            # in each row column 1 is the label and saved in index 0. so we need indexing to row 0 to get the label\n",
    "            digit_Name = row[0]\n",
    "\n",
    "            # in each row, column  2 to the end is the pixel of the image saved\n",
    "            image_array = np.asarray(row[1:])\n",
    "            \n",
    "            #reshaping the array from (784,) to (28,28) since image should be 2 dimension atleast\n",
    "            image_array = image_array.reshape(csv_image_shape_initialized)\n",
    "            # buld image object \n",
    "            new_image = Image.fromarray(image_array.astype('uint8'))\n",
    "            # Resize to the Image to the size we want\n",
    "            new_image = new_image.resize(image_shape_target)\n",
    "            \n",
    "            #convert integer value being alphabel, example, if zero then \"A\", if 1 then \"B\"\n",
    "            label = Alphabet_Mapping_List[int(digit_Name)]\n",
    "            \n",
    "            image_Path = image_folder_path + '/' + label + '/' + str(label) + '-' + str(count) + '.png'\n",
    "            new_image.save(image_Path)\n",
    "            count = count + 1\n",
    "\n",
    "            if count % 1000 == 0:\n",
    "                print (\"Images processed: \" + str(count))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:38:43.181792Z",
     "iopub.status.busy": "2022-10-19T04:38:43.180496Z",
     "iopub.status.idle": "2022-10-19T04:38:43.194281Z",
     "shell.execute_reply": "2022-10-19T04:38:43.192667Z",
     "shell.execute_reply.started": "2022-10-19T04:38:43.181732Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#load image from folder and return stacked numpy array for handwritten recognition\n",
    "def load_image(directory, image_folder_path=(24, 24)):\n",
    "    \n",
    "    '''\n",
    "    args :\n",
    "    - directory : directory path of all image folder saved\n",
    "    - image_folder_path : target image you want as return\n",
    "\n",
    "    return :\n",
    "    stacked image aray with the label \n",
    "    '''\n",
    "    \n",
    "    total_image = 0\n",
    "    label_names_list = [folder for folder in os.listdir(directory)]\n",
    "    \n",
    "    #Calculate how many image to make multidimensional Array\n",
    "    for label_name in label_names_list :\n",
    "        total_image += len(os.listdir(os.path.join(directory,label_name)))\n",
    "    #Define array of image and target\n",
    "    stack_of_image = np.empty((total_image,image_shape_target[0],image_shape_target[1]))\n",
    "    stack_of_label = np.empty(total_image)\n",
    "    \n",
    "    temp = total_image \n",
    "    for i, label_name  in enumerate(label_names_list) :\n",
    "        image_class_path = os.path.join(directory,label_name)\n",
    "    for image in os.listdir(image_class_path) :\n",
    "        image = os.path.join(image_class_path,image)\n",
    "        #Open Image\n",
    "        image = Image.open(image)\n",
    "        #Resize Image\n",
    "        resized_image = image.resize(image_shape_target)\n",
    "        resized_image_array = np.asarray(resized_image)\n",
    "        #Append to Array\n",
    "        stack_of_image[total_image-temp] = resized_image_array\n",
    "        stack_of_label[total_image-temp] = i\n",
    "        temp -= 1       \n",
    "    \n",
    "    return (stack_of_image, stack_of_label)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:38:43.455141Z",
     "iopub.status.busy": "2022-10-19T04:38:43.453765Z",
     "iopub.status.idle": "2022-10-19T04:38:43.464306Z",
     "shell.execute_reply": "2022-10-19T04:38:43.463449Z",
     "shell.execute_reply.started": "2022-10-19T04:38:43.455086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Image from csv and return stacked numpy array for handwritten recognition\n",
    "def csv_to_array(csv_path,csv_image_shape_initialized, image_shape_target):\n",
    "    \n",
    "    '''\n",
    "    something to note :\n",
    "    - don't include the header on the csv data\n",
    "    - each row save the image where the first column is the label followed the pixel value\n",
    "    - this function just good at minimize image not to enlarge. since interpolation used are good for minimize\n",
    "    \n",
    "    args :\n",
    "    csv_path : where the csv that will be loaded saved\n",
    "    csv_image_shape_initialized : image_shape saved on the csv\n",
    "    image_shape_target : size of the image you want as the output\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    count = 1\n",
    "    X_stacked = []\n",
    "    y_stacked = []\n",
    "    \n",
    "    with open(csv_path, newline='') as csvfile:\n",
    "        # make a object that can help to iterate over lines of CSV file\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        \n",
    "        # Iterate over lines\n",
    "        for row in reader:\n",
    "            # in each row column 1 is the label and saved in index 0. so we need indexing to row 0 to get the label\n",
    "            y_stacked.append(int(row[0]))\n",
    "\n",
    "            # in each row, column  2 to the end is the pixel of the image saved\n",
    "            image_array = np.asarray(row[1:])\n",
    "            \n",
    "            #reshaping the array from (784,) to (28,28) since image should be 2 dimension atleast\n",
    "            image_array = image_array.reshape(csv_image_shape_initialized)\n",
    "            # buld image object \n",
    "            new_image = Image.fromarray(image_array.astype('uint8'))\n",
    "            # Resize to the Image to the size we want\n",
    "            new_image = new_image.resize(image_shape_target)\n",
    "            \n",
    "            # Append to the list\n",
    "            X_stacked.append(np.array(new_image))\n",
    "            \n",
    "        X_stacked = np.array(X_stacked)\n",
    "        y_stacked = np.array(y_stacked)\n",
    "        \n",
    "    return X_stacked, y_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:38:56.073041Z",
     "iopub.status.busy": "2022-10-19T04:38:56.071250Z",
     "iopub.status.idle": "2022-10-19T04:38:56.076936Z",
     "shell.execute_reply": "2022-10-19T04:38:56.076111Z",
     "shell.execute_reply.started": "2022-10-19T04:38:56.073041Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#path of csv located\n",
    "csv_path = r\"C:/Users/Astrowest/Downloads/A_Z.csv\"\n",
    "#Image shape initialize by the data author\n",
    "csv_image_shape_initialized = (28,28)\n",
    "#Image shape you want as the output\n",
    "image_shape_target =(24,24)\n",
    "#Image path to loaded from\n",
    "image_folder_path = r\"/notebooks/Handwritten Recognition/data_input/A_Z Image\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-18T16:11:38.066254Z",
     "iopub.status.busy": "2022-10-18T16:11:38.065865Z",
     "iopub.status.idle": "2022-10-18T16:11:45.632117Z",
     "shell.execute_reply": "2022-10-18T16:11:45.630545Z",
     "shell.execute_reply.started": "2022-10-18T16:11:38.066227Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run this code to convert the CSV file to image \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcsv_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcsv_image_shape_initialized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_shape_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_folder_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mcsv_to_image\u001b[0;34m(csv_path, csv_image_shape_initialized, image_shape_target, image_folder_path)\u001b[0m\n\u001b[1;32m     49\u001b[0m label \u001b[38;5;241m=\u001b[39m Alphabet_Mapping_List[\u001b[38;5;28mint\u001b[39m(digit_Name)]\n\u001b[1;32m     51\u001b[0m image_Path \u001b[38;5;241m=\u001b[39m image_folder_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m label \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(label) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(count) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 52\u001b[0m \u001b[43mnew_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_Path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m count \u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py:2320\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2317\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2320\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/PngImagePlugin.py:1388\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1385\u001b[0m chunk(fp, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIEND\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run this code to convert the CSV file to image \n",
    "csv_to_image(csv_path,csv_image_shape_initialized, image_shape_target, image_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T03:13:58.740895Z",
     "iopub.status.busy": "2022-10-19T03:13:58.739232Z",
     "iopub.status.idle": "2022-10-19T03:13:58.891198Z",
     "shell.execute_reply": "2022-10-19T03:13:58.890456Z",
     "shell.execute_reply.started": "2022-10-19T03:13:58.740840Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_to_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Astrowest\\Downloads\\notebookaa5fa49a2d (2).ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Astrowest/Downloads/notebookaa5fa49a2d%20%282%29.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Run this code to load code from directory and saved to array for Handwritten recognition\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Astrowest/Downloads/notebookaa5fa49a2d%20%282%29.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X, y \u001b[39m=\u001b[39m image_to_array(image_folder_path, image_size\u001b[39m=\u001b[39m(\u001b[39m24\u001b[39m, \u001b[39m24\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_to_array' is not defined"
     ]
    }
   ],
   "source": [
    "# Run this code to load code from directory and saved to array for Handwritten recognition\n",
    "X, y = load_image(directory, image_folder_path=(24, 24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:39:03.815216Z",
     "iopub.status.busy": "2022-10-19T04:39:03.814040Z",
     "iopub.status.idle": "2022-10-19T04:42:14.075006Z",
     "shell.execute_reply": "2022-10-19T04:42:14.073503Z",
     "shell.execute_reply.started": "2022-10-19T04:39:03.815185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this code to Load code from csv and save to array for Handwritten recognition\n",
    "X, y = csv_to_array(csv_path,csv_image_shape_initialized, image_shape_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:42:14.077111Z",
     "iopub.status.busy": "2022-10-19T04:42:14.076713Z",
     "iopub.status.idle": "2022-10-19T04:42:14.241294Z",
     "shell.execute_reply": "2022-10-19T04:42:14.240265Z",
     "shell.execute_reply.started": "2022-10-19T04:42:14.077068Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x198d3d45990>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the image\n",
    "plt.imshow(X[2], cmap= 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening The Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image need to flattened before classify\n",
    "# (num_of_image,width, height) -> (num_of_image, width*height)\n",
    "X = X.reshape(X.shape[0], X.shape[1]* X.shape[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:42:14.252151Z",
     "iopub.status.busy": "2022-10-19T04:42:14.251877Z",
     "iopub.status.idle": "2022-10-19T04:42:14.363281Z",
     "shell.execute_reply": "2022-10-19T04:42:14.362072Z",
     "shell.execute_reply.started": "2022-10-19T04:42:14.252126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting between train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 123321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelining "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:42:14.373421Z",
     "iopub.status.busy": "2022-10-19T04:42:14.373025Z",
     "iopub.status.idle": "2022-10-19T04:42:14.380527Z",
     "shell.execute_reply": "2022-10-19T04:42:14.378990Z",
     "shell.execute_reply.started": "2022-10-19T04:42:14.373409Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "# Activate Intel Extension so the algorith can run faster\n",
    "patch_sklearn()\n",
    "\n",
    "# define the algorithm\n",
    "linearsvc =  LinearSVC(random_state=0, tol=1e-5)\n",
    "\n",
    "# so the step each image will follow this step before can be trained or inference\n",
    "svc_steps = [ \n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classify', linearsvc)\n",
    "]\n",
    "\n",
    "# build pipeline from the svc_steps\n",
    "svc_pipe = Pipeline(svc_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-19T04:42:14.382351Z",
     "iopub.status.busy": "2022-10-19T04:42:14.381947Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Astrowest\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classify&#x27;, LinearSVC(random_state=0, tol=1e-05))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;classify&#x27;, LinearSVC(random_state=0, tol=1e-05))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(random_state=0, tol=1e-05)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('classify', LinearSVC(random_state=0, tol=1e-05))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "svc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test data\n",
    "y_pred = svc_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision, Recall, F1-score and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-10-18T07:36:37.705572Z",
     "iopub.status.idle": "2022-10-18T07:36:37.706178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= SVC Model Report ===========================\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81      2751\n",
      "           1       0.81      0.66      0.73      1737\n",
      "           2       0.87      0.89      0.88      4760\n",
      "           3       0.75      0.67      0.71      2030\n",
      "           4       0.80      0.75      0.78      2267\n",
      "           5       0.92      0.78      0.85       241\n",
      "           6       0.80      0.71      0.75      1143\n",
      "           7       0.71      0.66      0.69      1407\n",
      "           8       0.86      0.82      0.84       230\n",
      "           9       0.76      0.67      0.71      1706\n",
      "          10       0.78      0.69      0.73      1101\n",
      "          11       0.92      0.95      0.93      2284\n",
      "          12       0.85      0.88      0.87      2449\n",
      "          13       0.78      0.78      0.78      3805\n",
      "          14       0.89      0.96      0.92     11611\n",
      "          15       0.86      0.91      0.88      3872\n",
      "          16       0.79      0.72      0.75      1164\n",
      "          17       0.77      0.74      0.76      2282\n",
      "          18       0.92      0.93      0.92      9705\n",
      "          19       0.90      0.94      0.92      4486\n",
      "          20       0.83      0.85      0.84      5792\n",
      "          21       0.85      0.88      0.87       844\n",
      "          22       0.79      0.76      0.77      2131\n",
      "          23       0.84      0.76      0.80      1329\n",
      "          24       0.81      0.81      0.81      2173\n",
      "          25       0.86      0.80      0.83      1191\n",
      "\n",
      "    accuracy                           0.85     74491\n",
      "   macro avg       0.83      0.80      0.81     74491\n",
      "weighted avg       0.85      0.85      0.85     74491\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"======================= SVC Model Report ===========================\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svc_model.sav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "pickle.dump(svc_pipe, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from disk\n",
    "svc_pipe = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "1366364e713644f841bea313cb18f744a0ebaaa298d6a31cfe150f1f10f27cac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
